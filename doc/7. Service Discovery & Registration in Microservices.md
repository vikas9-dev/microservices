# Service Discovery & Registration in Microservices

## 1. Understanding Internal Communication in Microservices

Let us explore one of the critical challenges that arise when building microservices applications: **internal communication** between microservices.

### A Quick Recap of Our Microservices Setup

So far, we have built three different microservices:

- **Accounts Microservice**
- **Loans Microservice**
- **Cards Microservice**

Each of these microservices is responsible for handling specific business logic, storing data, and processing incoming requests. Whenever an application interacts with these microservices, they execute the necessary logic and return an appropriate response.

### Deployment of Microservices in a Network

In real-world applications, microservices are not deployed in isolation on separate servers. Instead, they are hosted within a **common microservices network**. This allows them to communicate efficiently while remaining secure.

To regulate access to our microservices, we introduce a **single entry point**—the **API Gateway**. External clients (such as C1, C2, and C3) cannot communicate directly with the microservices. Instead, all incoming requests must pass through this API Gateway, which acts as a filter to enforce security, auditing, and logging. This ensures that only authorized traffic reaches the microservices.

### The Importance of Internal Communication

While the API Gateway handles **external traffic**, microservices often need to interact with each other internally. For example:

- An external request may arrive at the **Accounts Microservice**.
- To process the request, Accounts may need to fetch additional details from the **Loans** and **Cards** microservices.
- These interactions between microservices are referred to as **internal communication**.

In a microservices network, we classify traffic into two types:

- **External Communication:** Traffic entering from outside, passing through the API Gateway.
- **Internal Communication:** Traffic flowing between microservices within the network.

### Challenges in Internal Communication

Internal communication is not as straightforward as external API calls. It introduces several challenges, including:

- **Service Discovery:** How does one microservice locate another within the network?
- **Load Balancing:** Ensuring requests are distributed efficiently among service instances.
- **Fault Tolerance:** Handling failures when one microservice depends on another.
- **Latency & Performance:** Minimizing delays in inter-service communication.
- **Security & Authorization:** Ensuring that microservices interact securely without exposing vulnerabilities.

---

## 2. The Challenge of Service Discovery in Microservices

In this segment, we will explore another crucial challenge in building microservices: **service discovery and registration**.

So far, we have discussed four different challenges in microservices and how to overcome them. Now, we move on to **Challenge #5**:

- **How do microservices discover and register themselves in a microservices network?**

Before diving into solutions, let’s first understand the problem in detail.

### The Problem: How Do Microservices Locate Each Other?

All our microservices are deployed within a **microservices network**. When one microservice instance needs to communicate with another, it must locate it within this network. A common assumption is that each microservice has a fixed **endpoint (IP address + port number)** that other services can use to connect. While this might work in monolithic applications, microservices architecture presents additional challenges:

- Microservice containers are created and destroyed dynamically.
- Scaling up or down changes the number of service instances.
- Each time a microservice restarts, it may receive a **new IP address**.

Given these dynamic conditions, how can one microservice reliably find another? This brings us to the challenge of **service discovery**.

### The Problem: How Do New Instances Register Themselves?

Imagine a production environment where we initially deploy:

- 1 instance of the **Accounts Microservice**
- 1 instance of the **Loans Microservice**
- 1 instance of the **Cards Microservice**

Later, as traffic increases, we scale up to **5 instances of each service**. When new instances are added, they must:

- Register themselves in the network.
- Inform other microservices about their presence.

Without proper registration, the **Accounts Microservice** might think that only one instance of the **Loans Microservice** exists, while in reality, five instances are running. This lack of awareness can lead to inefficient communication and bottlenecks.

Similarly, when replacing an unhealthy instance with a new one, the new container will have a different **IP address**. If the system isn’t aware of these changes, it won’t be able to route traffic correctly.

### The Problem: Load Balancing Between Multiple Instances

Another challenge arises when multiple instances of a microservice exist. Suppose the **Accounts Microservice** needs to call the **Loans Microservice**, which has five running instances. The key questions here are:

- How does the **Accounts Microservice** decide which instance of the **Loans Microservice** to call?
- How do we ensure traffic is distributed evenly among all instances?

Without proper load balancing, one instance might receive all the traffic, becoming overloaded, while others remain idle. This results in poor performance and inefficient resource utilization.

### Introducing the Solution: Service Discovery, Registration, and Load Balancing

To tackle these challenges, we use established patterns and concepts:

1. **Service Discovery** – A mechanism that enables microservices to locate each other dynamically.
2. **Service Registration** – Ensures that new instances register themselves so they can be discovered by others.
3. **Load Balancing** – Distributes traffic evenly among multiple instances to prevent overload.

---

## 3. Challenges of Traditional Approaches in Microservices Communication

For a moment, let’s imagine a microservices environment without service discovery or service registration. In this scenario, we are forced to rely on traditional monolithic approaches for internal communication between services. This presents several challenges that can significantly impact the efficiency, scalability, and maintainability of our system.

### Direct Service Communication: The Traditional Way

In a typical web network, a service must know the exact location of another service to communicate with it. This is usually done using:

- An **IP address** (e.g., `127.54.37.23`)
- A **DNS name** or **domain name** as an abstraction over the IP address

Now, let’s consider a scenario where the **Accounts** microservice needs to communicate with the **Loans** microservice. For simplicity, assume there is only one instance of each service running.

- The **Accounts** microservice is deployed in a server, making it the **upstream service** because it depends on another service.
- The **Loans** microservice is the **downstream service**, acting as a dependency for Accounts.

To establish communication, the Accounts microservice has two options:

1. **Hardcoding the IP address** of the Loans service within its code.
2. **Using a DNS name**, which is mapped to the Loans service's IP address.

This works fine in a static environment where the Loans service always has the same IP address. However, in cloud environments, where services dynamically scale up or down, this approach introduces critical limitations.

### Why Traditional Communication Fails in Microservices

In a monolithic or SOA-based system, the number of services is limited, and their deployments are relatively stable. Maintaining a DNS-to-IP mapping is manageable. However, in a **microservices-based architecture**, where services are containerized and frequently redeployed, this approach becomes impractical due to:

#### 1. **Dynamic IP Changes and Scaling Issues**

- Microservices architectures involve **dynamic scaling** based on traffic demand.
- When new instances of a service are created or old ones are removed, their IP addresses change.
- **Hardcoded IPs become obsolete**, requiring constant updates to maintain service connectivity.

#### 2. **Load Balancing Limitations**

- Traditional load balancers require **static routing tables**, which do not adapt well to **frequent service scaling**.
- If a load balancer is not updated with new service instances, some requests may fail.
- Load balancers in traditional setups also introduce additional costs and potential **single points of failure**.

#### 3. **Manual Maintenance Complexity**

- Someone must **manually update DNS records** or routing tables whenever a microservice instance is created or removed.
- This is **not feasible** in a cloud-native environment where services scale dynamically and are often ephemeral (short-lived).

#### 4. **Inefficient Failover and High Latency**

- If a microservice instance goes down, the system must detect and remove it from the routing table.
- Traditional DNS resolution **does not provide real-time updates**, leading to delayed failover responses.

### The Need for a Better Approach

To overcome these limitations, cloud-native microservices rely on **service discovery mechanisms** and **dynamic load balancing** solutions, which automatically track service instances and distribute requests efficiently.

In the next section, we will explore how modern solutions like **Eureka, Consul, and Kubernetes Service Discovery** address these challenges, enabling seamless microservices communication without relying on static configurations.

---

## 4. Solving Microservices Communication Challenges with Service Discovery

In the previous section, we discussed the limitations of traditional load balancers in microservices and cloud-native applications. Now, let's explore how we can overcome these challenges using the **Service Discovery pattern**.

### What is Service Discovery?

Service Discovery is a pattern that helps microservices **automatically track, register, and locate** each other without relying on hardcoded IP addresses or static configurations. This is achieved through a **Service Registry**, which acts as a centralized database that maintains a list of all active service instances.

Whenever a new microservice instance starts, it **registers itself** with the service registry. Similarly, when a microservice instance is shut down or removed, it is **deregistered automatically**. This ensures that only active and healthy instances are discoverable by other services.

For example, if five instances of the **Loans** microservice are running, they all register with the service registry. The **Accounts** microservice can then query the registry to dynamically discover an available Loans service instance instead of relying on a hardcoded IP address.

### How Does Service Discovery Work?

Service Discovery consists of two main processes:

1. **Service Registration** – Each microservice instance registers its details (such as IP address and port) with the **Service Registry** upon startup.
2. **Service Lookup (Discovery)** – When another microservice needs to communicate, it queries the **Service Registry** to find the current, healthy instances of the target service.

This eliminates the need for manual updates whenever services scale up or down.

### Service Discovery and Load Balancing

Apart from helping with service registration, the **Service Registry also facilitates load balancing**. If multiple instances of a service are available, the registry ensures requests are distributed among them using a load-balancing strategy.

There are two approaches to Service Discovery:

#### 1. **Client-Side Service Discovery**

- The client (requesting microservice) queries the **Service Registry** directly to find available service instances.
- The client then selects an instance and communicates with it directly.
- **Example:** Netflix Eureka follows this approach.

#### 2. **Server-Side Service Discovery**

- The client sends a request to a **load balancer** (such as an API gateway or service mesh).
- The load balancer queries the **Service Registry** and routes the request to an available instance.
- **Example:** Kubernetes Service Discovery follows this model.

In this section, we will focus on **Client-Side Service Discovery**, while later in the course, we will explore **Server-Side Discovery** using Kubernetes.

### Components of Service Discovery

1. **Service Registry (Central Server):**

   - Maintains a list of all active microservices.
   - Similar to a **Config Server** but for service addresses instead of configurations.

2. **Service Registration Process:**

   - When a microservice starts, it registers its IP and port with the **Service Registry**.
   - It also sends periodic **heartbeat signals** to confirm its availability.

3. **Service Deregistration:**
   - If a microservice fails or shuts down, the **Service Registry** removes its details.
   - If no heartbeat signals are received, the registry assumes the service is unhealthy and removes it automatically.

### Why Service Discovery is Essential

- **Eliminates Hardcoded IP Addresses:** Services dynamically discover each other.
- **Supports Auto-Scaling:** As instances increase or decrease, the registry keeps track.
- **Improves Reliability:** Unhealthy services are automatically removed.
- **Enhances Load Balancing:** Requests are intelligently distributed among healthy instances.

### Conclusion

Service Discovery and Service Registration solve the fundamental problem of **how microservices communicate in a dynamic environment**. By implementing a **centralized service registry**, we ensure seamless interaction between services, even as they scale up or down.

In the next section, we will dive deeper into **Client-Side Service Discovery** and see it in action.

---

## 5. Client-Side Service Discovery in Microservices

Previously we explored the concept of service discovery and service registration, which help solve communication challenges in microservices. We also introduced two approaches to implementing service discovery:

1. **Client-Side Service Discovery**
2. **Server-Side Service Discovery**

Let's focus on **Client-Side Service Discovery**, explaining how it works and how it can be implemented in microservices.

---

### What is Client-Side Service Discovery?

Client-Side Service Discovery is an approach where microservices are responsible for registering themselves with a **Service Registry** upon startup and deregistering when they shut down. This ensures that an updated list of available services is maintained dynamically.

When a microservice needs to communicate with another service, it queries the **Service Registry** to obtain the available service instances. If multiple instances exist, the requesting microservice selects one using a **load balancing strategy**.

---

### How Client-Side Service Discovery Works

1. **Service Registration**

   - Before launching microservices, the **Service Registry** must be running.
   - Each microservice instance registers itself with the registry upon startup, providing details such as **IP address, hostname, and port number**.
   - The service periodically sends **heartbeat signals** to confirm its availability.

2. **Service Discovery**

   - When a microservice (e.g., `Accounts` service) wants to communicate with another (`Loans` service), it queries the **Service Registry** for available instances.
   - The **Service Registry** responds with a list of available instances of the `Loans` service.

3. **Client-Side Load Balancing**

   - The requesting microservice (`Accounts` service) is responsible for selecting one instance from the list.
   - It applies a **load balancing strategy** such as:
     - **Round Robin**: Requests are distributed sequentially.
     - **Weighted Round Robin**: Requests are distributed based on assigned weights.
     - **Least Connections**: The instance with the fewest connections is selected.
     - **Custom Algorithms**: Custom strategies can also be implemented.

4. **Caching Service Details**
   - To optimize performance, the requesting microservice caches the discovered service instances.
   - Cached details reduce dependency on the Service Registry for each request.
   - The cache is refreshed periodically (e.g., every 10-20 seconds) or when an error occurs, triggering an update.

---

### Advantages of Client-Side Service Discovery

- **Flexibility in Load Balancing:** Different strategies can be applied to optimize traffic distribution.
- **Reduced Dependency on External Load Balancers:** Eliminates the need for traditional load balancers.
- **Improved Performance:** Caching reduces the load on the Service Registry and speeds up service lookups.

---

### Challenges of Client-Side Service Discovery

- **Increased Complexity for Developers:** Each microservice must include logic for service registration, discovery, and load balancing.
- **Need for a Centralized Service Registry:** A separate server must be maintained for service registration and discovery.

---

### Comparison with Server-Side Service Discovery

- **Client-Side Discovery** is suitable for projects with limited budgets that cannot afford Kubernetes clusters.
- **Server-Side Discovery** is preferred for Kubernetes-based deployments, as Kubernetes handles service registration and discovery automatically.

### Simplifying Client-Side Service Discovery with Spring Cloud

While implementing client-side service discovery from scratch may seem complex, **Spring Cloud** simplifies this process. Spring Cloud provides built-in solutions for service registration, discovery, and load balancing, which we will explore in upcoming discussions.

---

## 6. **Client-Side Service Discovery in Microservices**

Spring Cloud provides a simple and efficient way to achieve service discovery and registration. Let us explore its implementation and realize how seamless the process can be.

### Key Components of Client-Side Service Discovery

To achieve service discovery and load balancing, we will leverage several Spring Cloud components:

#### **1. Eureka Server (Spring Cloud Netflix Eureka)**

- Acts as a central service responsible for service registration and discovery.
- Functions as a service discovery agent in the microservices architecture.

#### **2. Spring Cloud Load Balancer**

- Enables client-side load balancing.
- Replaces Netflix Ribbon, which is now in maintenance mode and no longer actively developed.

#### **3. Netflix Feign Client**

- Provides a simple and declarative way to make REST API calls between microservices.
- Functions similarly to `RestTemplate` and `WebClient` in the Spring ecosystem.

### Alternative Technologies

While we are using Spring Cloud components, there are other service discovery tools available in the industry:

- **Etcd**
- **Consul**
- **Apache Zookeeper**

Since we are building microservices with Spring Boot, using Spring Cloud components ensures seamless integration and ease of implementation.

### Evolution of Client-Side Load Balancing

In older projects using earlier versions of Spring Boot, Netflix Ribbon was commonly used. However, it is now deprecated in favor of **Spring Cloud Load Balancer**, which is the preferred and actively maintained solution.

### Advantages of Client-Side Service Discovery

- **High Availability:** Multiple nodes of service discovery can be deployed, reducing the risk of downtime.
- **Dynamic Configuration Updates:** IP addresses and load balancer configurations update dynamically without affecting microservices communication.
- **Fault Tolerance and Resilience:** Service discovery mechanisms enhance reliability by providing failover and recovery mechanisms.

### The Role of Netflix in Spring Cloud

Spring Cloud Netflix originated from libraries developed by Netflix, such as:

- **Eureka (Service Discovery)**
- **Ribbon (Load Balancing - now replaced by Spring Cloud Load Balancer)**
- **Hystrix (Fault Tolerance - now replaced by Resilience4j)**

Netflix open-sourced these components in 2012, and they were integrated into Spring Cloud in 2015. Since then, the project has evolved, and Netflix itself has adopted Spring Boot and Spring Cloud Netflix for its microservices architecture.

### Conclusion

We are using modern, stable, and widely adopted technologies in our course. Netflix's adoption of these technologies is a testament to their reliability and scalability. Further reading:- [Netflix OSS and Spring Boot](https://netflixtechblog.com/netflix-oss-and-spring-boot-coming-full-circle-4855947713a0)

---

## 7. Setting Up a Service Discovery Agent with Eureka

Let us build a **service discovery agent** using **Eureka** from the **Spring Cloud Netflix** project.

### Project Setup

Since this is a new section, we create a new folder **section 8** inside the workspace. Instead of copying code from **section 7** (which uses MySQL), we copy the code from **section 6 v2**, as we have decided to use **H2 database**.

After setting up the folder, we open it in **IntelliJ IDEA**, remove unnecessary dependencies like **Spring Cloud Bus** and **RabbitMQ** from all microservices (`accounts`, `loans`, `cards`), and clean up the **application.yml** files accordingly.

### Creating the Eureka Server

To create the Eureka Server:

1. Visit [start.spring.io](https://start.spring.io/).
2. Use **Maven** as the build tool and **Java** as the language.
3. Select the latest stable **Spring Boot** version.
4. Set:
   - **Group**: `com.knowprogram`
   - **Artifact & Name**: `eurekaserver`
   - **Description**: `Service Discovery Agent for PeopleBank Microservices`
   - **Java Version**: 17
5. Add dependencies:
   - `Eureka Server`
   - `Config Client`
   - `Spring Boot Actuator`
6. Generate the project, extract the ZIP, and move it into `section 8`.

### Loading the Eureka Server

In **IntelliJ IDEA**:

- Add the **Eureka Server** as a Maven project.
- Open the **main class** and add `@EnableEurekaServer`.
- Allow **Maven dependencies** to download.

### Configuring the Eureka Server

#### 1. Update `application.yml`

- Set the **application name**:
  ```yaml
  spring:
    application:
      name: eureka-server
  ```
- Connect to the **Config Server**:
  ```yaml
  spring:
    config:
      import: "optional:configserver:http://localhost:8071"
  ```
- Enable health checks for **Docker Compose**:
  ```yaml
  management:
    endpoints:
        web:
        exposure:
            include: "*"
    health:
        readiness-state:
        enabled: true
        liveness-state:
        enabled: true
    endpoint:
        health:
        probes:
            enabled: true
  ```

#### 2. Add Configuration in GitHub Repository

Inside the `peoplebank-config` repository, create a file **eurekaserver.yml**:

```yaml
server:
  port: 8070

eureka:
  instance:
    hostname: localhost
  client:
    fetch-registry: false
    register-with-eureka: false
    service-url:
      defaultZone: "http://${eureka.instance.hostname}:${server.port}/eureka"
```

### Running the Eureka Server

1. **Start the Config Server** (`localhost:8071`).
2. Verify Eureka properties using:
   ```
   localhost:8071/eurekaserver/default
   ```
3. Start the **Eureka Server** in debug mode.
4. Verify Eureka at (in Browser): [http://localhost:8070](localhost:8070)

At this stage, the Eureka dashboard will be empty since no microservices have registered yet. The next step is to integrate our microservices (`accounts`, `loans`, `cards`) with Eureka.

---

## 8. Registering Microservices with Eureka

Let us see how to connect the Accounts Microservice to Eureka.

### Step 1: Adding the Eureka Client Dependency  

To enable service registration, we need to add the **Eureka Client** dependency to our `accounts` microservice.  

   ```xml
   <dependency>
      <groupId>org.springframework.cloud</groupId>
      <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>
    </dependency>
   ```

### Step 2: Configuring `application.yml`  

Now, we need to modify the `application.yml` file of the **accounts** microservice to register it with Eureka.  

#### Eureka Configuration  

```yaml
eureka:
  instance:
    preferIpAddress: true
  client:
    fetchRegistry: true
    registerWithEureka: true
    serviceUrl:
      defaultZone: http://localhost:8070/eureka/
```

- `fetchRegistry: true` → Ensures the microservice fetches the **registry details** to communicate with other services. The default vale of this property is `true`, therefore it is optional.
- `registerWithEureka: true` → Allows the microservice to **register itself** with Eureka. The default vale of this property is `true`, therefore it is optional.
- `defaultZone` → Defines the **Eureka server URL** (must match the one in `eurekaserver` project).  
- `preferIpAddress: true` → Ensures the service registers using its **IP address** instead of hostname.  

#### Actuator & Info Configuration  

We also add **actuator** properties to expose service information:  

```yaml
info:
  app:
    name: accounts
    description: PeopleBank Accounts Application
    version: 1.0.0

management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    health:
      show-details: always
  info:
    env:
      enabled: true
```

- `info.app` → Displays **service details** in the **Eureka dashboard**.  
- `management.endpoints.web.exposure.include: "*"` → Exposes all **actuator endpoints**.  
- `management.info.env.enabled: true` → Enables **environment information**.  

#### Enabling Shutdown Endpoint  

To allow graceful shutdown via Actuator, we enable the **shutdown endpoint**:  

```yaml
management:
  endpoints:
    web:
      exposure:
        include: "*"
  endpoint:
    shutdown:
      enabled: true

# define it at the root level also
endpoints:
    shutdown:
      enabled: true
```

- This enables `/actuator/shutdown` for **graceful service termination**.  

### Step 3: Running the Accounts Microservice  

1. **Start the Config Server** (`localhost:8071`).  
2. **Start the Eureka Server** (`localhost:8070`).  
3. **Start the Accounts Microservice** (`localhost:8080`).  

Upon startup, the service should **register** with Eureka and send **heartbeat signals** every **30 seconds**. You will see a **204 registration response** in the logs.  

### Step 4: Verifying in Eureka Dashboard  

1. Open the Eureka Dashboard:  
   ```
   http://localhost:8070
   ```
2. You should see `accounts` listed under **Instances Registered with Eureka**.  
3. Clicking on `accounts` will show details like:  
   - **App Name:** accounts  
   - **Description:** PeopleBank Accounts Application  
   - **Version:** 1.0.0  
   - **IP Address Registration**  

Now that `accounts` is registered, please repeat these steps for:  
- **loans** microservice  
- **cards** microservice  

---

## 9. 