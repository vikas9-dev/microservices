# Handle Deployment, Portability & Scalability of Microservices using Docker

## 1. Microservices Challenges & Containerization

- **Overcoming Deployment, Portability & Scalability Issues**:-
  Building microservices introduces challenges in **deployment**, **portability**, and **scalability**. Unlike monolithic applications, microservices require efficient deployment strategies, seamless movement across environments, and dynamic scaling.
- **Solution: Containerization with Docker**:- Containers package applications with all dependencies, ensuring consistency across environments. Docker enables **isolated, portable, and scalable** microservices, optimizing resource utilization without manual intervention.
- **Shipping Containers Analogy**:- Just like shipping containers streamline logistics, **Docker containers** provide isolated environments for microservices, allowing efficient deployment and scaling.

---

## 2. Virtual Machines vs. Containers: The Shift to Docker

### **The Evolution of Deployment**

Before cloud computing, organizations relied on physical servers, installing operating systems and deploying applications manually. Later, cloud providers introduced **Virtual Machines (VMs)**, allowing multiple virtual environments on a single physical server via **hypervisors**.

### **Challenges with Virtual Machines**

1. **Heavy Resource Consumption** – Each VM has its own **Guest OS**, consuming RAM and storage.
2. **Slow Scaling** – Spinning up a new VM takes time, delaying service availability.
3. **Complex Dependencies** – Deploying multiple microservices with different requirements (e.g., Java 8 vs. Java 17) in the same VM leads to conflicts.

### **Containers: A Lightweight Alternative**

Unlike VMs, **containers** share the Host OS and utilize a **Container Engine (like Docker)**, making them:

- **Faster** – Start in seconds, unlike VMs which take minutes.
- **Lightweight** – No need for a separate OS per microservice.
- **Portable** – Can be deployed across environments effortlessly.
- **Isolated** – Each container has its own dependencies and virtual network.

### **Why Containers Over VMs?**

With **Docker**, microservices can be packaged with all required dependencies, ensuring consistency across environments. Containers solve **deployment, portability, and scalability** issues, making them the preferred choice over VMs for modern microservice architectures.

---

## 3. Understanding Containers and Docker

### **What is a Container?**

A **container** is a lightweight, isolated environment that includes an application and all its dependencies, allowing it to run consistently across different computing environments. Unlike virtual machines, containers share the **host operating system kernel**, making them faster and more efficient.

### **What is Software Containerization?**

**Containerization** is an **OS-level virtualization method** that allows multiple containers to run on the same machine while remaining isolated. This eliminates compatibility issues and ensures portability across different environments.

### **What is Docker?**

Docker is an **open-source platform** that enables developers to package applications into **Docker images**, which can then be run as **Docker containers**. It simplifies **deployment, scaling, and management** of applications.

### **How Containers Differ from Virtual Machines?**

- **Virtual Machines (VMs)** require a full Guest OS for each instance.
- **Containers** share the Host OS, making them **lightweight, faster, and more scalable**.

### **Key Linux Concepts in Containerization**

In containerization, Linux features such as namespaces and cgroups play a crucial role in providing isolation and resource management.

- **Namespaces**: Linux namespaces allow for the creation of isolated environments within the operating system. Each container has its own set of namespaces, including process, network, file system/mount/storage, IPC (inter-process communication) and user namespace. These namespaces ensure that processes within a container only aware of and can interact with resources within their specific namespace, providing a level of isolation.
- **Control Groups (cgroups)**: Manage resource allocation (CPU, memory) to prevent one container from monopolizing system resources. The cgroups provide resource management and allocation capabilities for containers. They allow administrators to control and limit the resources (such as CPU, memory, disk I/O, and network bandwidth) that containers can consume. By using cgroups, container runtimes can enforce resource restrictions and prevent one container from monopolizing system resources, ensuring fair allocation among containers.

### **Running Docker on Different OS**

On **Linux**, Docker runs natively. On **Windows and macOS**, Docker installs a lightweight **Linux virtual machine** to ensure compatibility. When we opt for Docker Desktop for Mac or Windows, only the Docker client is installed on the host MAC or Windows machine. Behind the scenes, a lightweight virtual machine is configured with Linux, and the Docker server component is installed within that virtual machine.

when we utilize the Docker CLI to execute commands, we are actually interacting with a Docker server running on a separate machine, which in this case is the Linux-based virtual machine.

---

## 4. Understanding Docker Architecture and Its Key Components

### **1️⃣ Docker Client**

The **Docker Client** is the interface used to communicate with the **Docker Server**. There are two ways to issue commands:

- **Docker CLI**: The most commonly used approach for executing Docker commands in the terminal.
- **Docker Remote API**: Allows applications to interact with Docker using API calls.

### **2️⃣ Docker Server (Docker Host)**

The **Docker Server** (or **Docker Host**) runs the **Docker Daemon**, which processes commands from the client and manages:

- **Docker Images** – Packaged applications containing all dependencies.
- **Docker Containers** – Running instances of Docker Images, representing active microservices.

### **3️⃣ Docker Registry**

A **Docker Registry** stores and distributes Docker Images. Common registries include:

- **Docker Hub** (Public/Private Repositories)
- **Cloud-based Registries**: AWS Elastic Container Registry (ECR), Google Container Registry (GCR), Azure Container Registry (ACR), and GitHub Container Registry.

### **How Docker Works?**

1. The **Docker Client** sends an instruction to run a container.
2. The **Docker Server** checks if the required image exists locally; if not, it fetches it from a **Docker Registry**.
3. A **Docker Container** is created from the image and starts running the application.
4. The application is now accessible via its assigned port.

### **Why Use Docker?**

- Simplifies application deployment.
- Provides consistency across different environments.
- Enables efficient resource utilization.
- Supports fast scaling and portability.

---

## 5. Generating Docker Images for Microservices

Are you ready to generate a Docker image from our microservice? By converting our microservices into Docker images, we make them incredibly lightweight, enhancing their deployment portability and scalability.

To generate a Docker image from a web application or a Spring Boot application, there are three commonly used approaches in the industry. In this section, we will explore these three approaches, and by the end, we will select one to use for the rest of this course.

### 1️⃣ Dockerfile Approach

The first and most traditional approach is using a **Dockerfile**. This method requires writing a set of instructions inside a `Dockerfile`, which guides the Docker server in creating a Docker image.

- This approach provides full control over the image-building process.
- It requires learning Docker syntax and best practices.
- This is the approach we will use to generate a Docker image for the **Accounts Microservice**.

### 2️⃣ Buildpacks Approach

The second approach utilizes **Buildpacks**. With this method, you don't need to write a `Dockerfile` or provide manual instructions to the Docker server. Instead, you can generate a Docker image with a single Maven command, leveraging Buildpacks behind the scenes.

- Buildpacks is a project initiated by **Heroku** and **Pivotal**, incorporating best practices learned over the years.
- It simplifies the containerization process by eliminating the need for low-level Docker commands.
- This is the approach we will use to generate a Docker image for the **Loans Microservice**.

### 3️⃣ Google Jib Approach

The third approach is **Google Jib**, an open-source Java tool developed by Google. Jib provides an efficient way to create Docker images using a Maven plugin, without requiring a `Dockerfile`.

- Jib streamlines the image creation process, making it faster and easier.
- It eliminates the need for writing low-level Docker configurations.
- We will use this approach to generate a Docker image for the **Cards Microservice**.

---

## 6. Generate Docker Image of Accounts microservice with Dockerfile

### Generating a JAR File for the Accounts Microservice

There are three different Maven projects in our system: **Accounts**, **Cards**, and **Loans**. As the next step, we will focus on the **Accounts Microservice** and generate a Docker image using **Approach 1 (Dockerfile)**.

#### Configuring the `pom.xml` for Packaging

To ensure that our microservice is packaged correctly, we need to update the `pom.xml` file:

- Set the **packaging type** to `jar`.
- This tells Maven to package the Spring Boot application as a JAR file instead of a WAR file.

```
<groupId>com.knowprogram</groupId>
<artifactId>accounts</artifactId>
<version>0.0.1-SNAPSHOT</version>
<name>accounts</name>
<description>Microservice for Accounts</description>

<!-- Include this -->
<packaging>jar</packaging>
```

Since we are generating a Docker image, using JAR format is the best practice because it simplifies deployment and execution.

#### Running Maven Commands to Build the Project

Once the configuration is updated, we will follow these steps:

1. **Open the Terminal in the Accounts Microservice Folder**

   - Navigate to the `accounts` microservice directory where `pom.xml` is present.
   - Open the terminal in this directory.

2. **Verify Maven Installation**  
   Before proceeding, confirm that Maven is installed by running:

   ```sh
   mvn -version
   ```

   This should display the installed Maven version, ensuring it is set up correctly.

3. **Build the Project Using Maven**  
    Run the following Maven command to compile and package the Spring Boot application:

   ```sh
   mvn clean install
   ```

   - This command will compile the code, run unit tests, and generate a JAR file inside the `target/` folder.
   - Ensure that your `pom.xml` has the **Spring Boot Maven Plugin** configured, as it is required for packaging.

   ```xml
   <build>
    <plugins>
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-compiler-plugin</artifactId>
            <!-- (Optional) Set your Java version -->
            <configuration>
                <source>17</source>
                <target>17</target>
            </configuration>
        </plugin>

        <plugin>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-maven-plugin</artifactId>
        </plugin>
    </plugins>
   </build>
   ```

4. **Verify the Generated JAR File**  
   After a successful build, navigate to the `target/` folder and check for a JAR file: `accounts-0.0.1-SNAPSHOT.jar`
   - This JAR file contains all dependencies and the embedded Tomcat server, except for the Java runtime.
   - The name of the JAR is derived from the `artifactId` and `version` specified in `pom.xml`.

#### Running the Application with Maven

To start the microservice using Maven, execute:

```sh
mvn spring-boot:run
```

- This command looks for the JAR file and starts the Spring Boot application.
- The service should start on **port 8080** by default.
- You can test it using **Postman** or by invoking the APIs from a browser.

#### Running the Application with Java

Instead of using Maven, you can start the application with a **Java command**, which is useful for Dockerization:

```sh
java -jar target/accounts-0.0.1-SNAPSHOT.jar
```

- This eliminates the need for Maven inside the Docker container.
- The microservice should start successfully and be accessible via APIs.

Now that we have a successfully built JAR file, we are ready to write a **Dockerfile** to containerize our microservice. Now, we will create a **Dockerfile** and use it to generate a Docker image for the **Accounts Microservice**.

---

### Writing a Dockerfile for the Accounts Microservice

Before writing a **Dockerfile**, ensure that your **Accounts Microservice** is stopped by pressing `Ctrl + C` in the terminal. Also, make sure that **Docker is running** on your system. You can verify this by checking the Docker icon in your system tray (Windows) or menu bar (Mac).

#### **Creating the Dockerfile**

1. **Navigate to the `accounts` microservice directory.**
2. **Create a new file named `Dockerfile`** (without any extensions like `.txt` or `.xml`).
3. **Open the file and add the following instructions:**

#### **Dockerfile for Accounts Microservice**

```dockerfile
# Use an official OpenJDK base image
FROM openjdk:17-jdk-slim

# Copy the application JAR to the Docker image
COPY target/accounts-0.0.1-SNAPSHOT.jar accounts.jar

# Command to run the application
ENTRYPOINT ["java", "-jar", "accounts.jar"]
```

### **Understanding the Dockerfile Instructions**

- **`FROM openjdk:17-jdk-slim`** → Uses a lightweight Java 17 image as the base.
- **`COPY target/accounts-0.0.1-SNAPSHOT.jar accounts.jar`** → Copies the built JAR file into the container.
- **`ENTRYPOINT ["java", "-jar", "accounts.jar"]`** → Specifies the command to start the Spring Boot application inside the container.

---

### Building a Docker Image for the Accounts Microservice

Now that our **Dockerfile** is ready, the next step is to use it to generate a **Docker image** for the **Accounts Microservice**.

#### **Verifying Docker Installation**

Before running the build command, ensure that Docker is installed and running by executing:

```sh
docker version
```

This command should display both the **client** and **server** versions of Docker, confirming that it is properly set up.

#### **Building the Docker Image**

Run the following command from the **Accounts Microservice** directory (where the `Dockerfile` is located):

```sh
docker build -t <your-dockerhub-username>/accounts:S4 .
```

- `docker build` → Initiates the image build process.
- `-t <your-dockerhub-username>/accounts:S4` → Assigns a **name** (`accounts`) and a **tag** (`S4`).
- `.` → Refers to the current directory, where the `Dockerfile` is located.

#### **Understanding the Build Process**

- Docker first downloads the **OpenJDK 17 base image** from Docker Hub.
- It then **copies the JAR file** from the `target/` folder into the image.
- Finally, it sets the **entry point** to run the JAR file when a container is created.

#### **Listing Docker Images**

Once the build is complete, check the available images by running:

```sh
docker images
```

This will list all images, including:

- The **Accounts Microservice image** with the tag `S4`.
- The **image size**, which depends on the dependencies and base image.

```sh
$ docker images
REPOSITORY           TAG       IMAGE ID       CREATED         SIZE
vikas9dev/accounts   s4        18cdd03adfc0   7 minutes ago   760MB
```

#### **Inspecting the Docker Image**

For more details about the generated image, use:

```sh
docker inspect <image-id>
```

This provides information such as:

- **Base image** (`OpenJDK 17`)
- **Entry point** (`java -jar accounts.jar`)
- **Operating system** (`Linux`)

---

### Running a Docker Container for the Accounts Microservice

Now that we have successfully built a **Docker image** for our **Accounts Microservice**, the next step is to run a **Docker container** from this image.

#### **1. Running the Docker Container**

Execute the following command to create and run a container from the Docker image:

```sh
docker run -p 8080:8080 <your-dockerhub-username>/accounts:S4
```

- `docker run` → Creates a new container from the image.
- `-p 8080:8080` → Maps **port 8080 of the container** to **port 8080 on the local machine**.
- `<your-dockerhub-username>/accounts:S4` → Specifies the Docker image to use.

```sh
docker run -p 8080:8080 vikas9dev/accounts:s4
```

Once executed, the **Accounts Microservice** will start inside the container on **port 8080**.

#### **2. Testing the Running Container**

- Use **Postman** or a browser to send a request to: `http://localhost:8080`
- If everything is set up correctly, you should receive a **successful response** from the microservice.

#### **3. Running the Container in Detached Mode**

By default, the container runs in **foreground mode**, preventing other commands from being executed in the terminal. To run it in **detached mode**, use:

```sh
docker run -d -p 8080:8080 <your-dockerhub-username>/accounts:S4
```

- `-d` → Runs the container in **detached mode**, allowing the terminal to remain free for other commands.

```sh
$ docker run -d -p 8080:8080 vikas9dev/accounts:s4
60be723defd82f96c95ad58ab743f71a91813acc80f58da2208758856b475e87
```

#### **4. Checking Running Containers**

To list all **active** containers, use:

```sh
docker ps
```

This will display:

- **Container ID**
- **Image name**
- **Port mappings**

```sh
$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
60be723defd8 vikas9dev/accounts:s4 "java -jar /accounts…" 24 seconds ago Up 23 seconds 0.0.0.0:8080->8080/tcp kind_knuth
```

To see the stopped containers, use:

```sh
docker ps -a
```

#### **5. Stopping and Restarting Containers**

To **stop** a running container, use:

```sh
docker stop <container-id>
```

To **restart** an existing container, use:

```sh
docker start <container-id>
```

#### **6. Running Multiple Containers**

You can start multiple instances of the microservice by mapping different ports:

```sh
docker run -d -p 8081:8080 <your-dockerhub-username>/accounts:S4
```

This will start a second container on **port 8081**, while the first one runs on **port 8080**.

#### **7. Viewing Logs and Inspecting Containers**

To view logs of a running container:

```sh
docker logs <container-id>
```

To inspect container details:

```sh
docker inspect <container-id>
```

#### **8. To see the docker image files of the running docker container**

```sh
docker exec -it <container-id> sh
```

Example:-

```sh
docker exec -it 0013c3848d8e sh
# ls -al
```

#### **9. To Copy Files from a Running Container to Local System**

```sh
docker cp <container-id>:<container-path> <local-path>
```

Example:-

```sh
docker cp my-container:/app/logs ./logs
```

#### **10. Delete a Stopped Container**

```sh
docker rm <container-id>
```

To delete multiple stopped containers at once:

```sh
docker rm <container-id1> <container-id2>
```

To delete all stopped containers:

```sh
docker rm $(docker ps -aq)  # Remove all stopped containers
```

Or,

```sh
docker container prune
```

#### **10. Force Delete a Running Container**

```sh
docker rm -f <container-id> # Force delete a running container
```

To delete all running & stopped containers:

```sh
docker rm -f $(docker ps -aq)  # Remove all stopped containers
```

### **Understanding Port Mapping**

By default, Docker containers run in an **isolated network**. To make them accessible, **port mapping** is used:

```sh
docker run -p <external-port>:<container-port> <image-name>
```

For example,

```sh
docker run -p 8081:8080 <your-dockerhub-username>/accounts:S4
```

- **`8081` (external port)** → The port accessible from the local system.
- **`8080` (container port)** → The port inside the container.

---

### Limitations of the Dockerfile Approach

Now that we have successfully built a **Docker image** using a **Dockerfile**, it's important to understand its **limitations**. While this method works, it comes with certain challenges that make it less ideal for developers.

#### **Challenges of Using a Dockerfile**

1. **Requires Docker Expertise** – Developers must learn Docker commands, image structures, and best practices, which can be complex.
2. **Manual Configuration** – Writing efficient Dockerfiles requires **optimization techniques** like caching, compression, and security hardening.
3. **Scalability Issues** – Each microservice needs a separate Dockerfile, making maintenance difficult for large applications.
4. **Security Concerns** – Ensuring that Docker images are **secure and free from vulnerabilities** requires extra effort.

#### **A Better Alternative: Buildpacks & Google Jib**

To overcome these challenges, **Buildpacks** and **Google Jib** were developed, allowing developers to **automate** Docker image creation **without writing a Dockerfile**. These tools simplify the process, improve efficiency, and follow best practices automatically.

---

## 7. Generating a Docker Image Using Buildpacks

After exploring the **Dockerfile** approach, it's time to look at a more developer-friendly way to build Docker images: **Buildpacks**.

### **What is Buildpacks?**

Buildpacks is a technology developed by **Heroku** and later improved by **Pivotal** and the **Cloud Native Computing Foundation (CNCF)**. It allows developers to **convert application source code into a Docker image** without writing a **Dockerfile**.

With Buildpacks:

- You don't need to define low-level Docker instructions.
- A **single Maven command** can generate a **Docker image** effortlessly.
- The framework automatically **scans dependencies** and **optimizes** the image for **performance, security, and size**.

### **Why Use Buildpacks Instead of a Dockerfile?**

Unlike the Dockerfile approach, which requires **Docker expertise**, Buildpacks takes care of best practices **automatically**:  
✅ **Optimized Image Size** – Compresses and caches layers efficiently.  
✅ **Security Compliance** – Follows security standards during image creation.  
✅ **Multi-Language Support** – Works with Java, Python, Node.js, Go, Ruby, PHP, and more.

### **How to Generate a Docker Image Using Buildpacks**

For demonstration, we will use **Loans Microservice** and follow these steps:

1. **Configure `pom.xml`**

   - Ensure **Spring Boot Maven Plugin** is present.
   - Define the **image name** inside the `<configuration>` section:

     ```xml
     <configuration>
         <image>
             <name>${project.artifactId}</name>
         </image>
     </configuration>
     ```

   - Replace `artifactId` dynamically instead of hardcoding the service name.

   Example:-

   ```xml
   <plugin>
     <groupId>org.springframework.boot</groupId>
     <artifactId>spring-boot-maven-plugin</artifactId>
     <configuration>
       <image>
         <name>vikas9dev/${project.artifactId}:s4</name>
       </image>
     </configuration>
   </plugin>
   ```

2. **Run the Maven Command**  
   Execute the following command to build a Docker image:

   ```sh
   mvn spring-boot:build-image
   ```

   - This triggers Buildpacks to generate a **Docker image** automatically.
   - The first run may take a few minutes as it downloads necessary **Paketo Buildpacks**.

3. **Verify the Generated Docker Image**  
   Run:

   ```sh
   docker images
   ```

   - You should see the **Loans Microservice image** built with **Buildpacks**.
   - Typically, Buildpacks **optimizes image size**, making it smaller than a manually created Dockerfile image.

4. **Run the Container**  
   Start the container using:

   ```sh
   docker run -d -p 8090:8090 <your-dockerhub-username>/loans:S4
   ```

   - The **Loans Microservice** will now run inside a Docker container at **port 8090**.

Buildpacks provides a **simpler, automated, and production-ready** way to generate Docker images without manually handling Dockerfile complexities.

---

## 8. Generating a Docker Image Using Google Jib

In your Maven Java project, add the plugin to your pom.xml:

```xml
<project>
  ...
  <build>
    <plugins>
      ...
      <plugin>
        <groupId>com.google.cloud.tools</groupId>
        <artifactId>jib-maven-plugin</artifactId>
        <version>3.4.5</version>
        <configuration>
          <to>
            <image>vikas9dev/${project.artifactId}:s4</image>
          </to>
        </configuration>
      </plugin>
      ...
    </plugins>
  </build>
  ...
</project>
```

Go the Cards Microservice and run the following command:

```sh
mvn compile jib:dockerBuild
```

Run the image:-

```sh
docker run -d -p 9000:9000 vikas9dev/cards:s4
```

Using JIB we can generate the docker image even if we don't have docker installed on our system. If we want to generate the docker image without installing the docker into our local system then we can use the following command:-

```sh
mvn compile jib:build
```

The above command will generate the docker image without installing the docker into our local system.

---

## 9. Choosing the Right Approach for Generating Docker Images

We explored the three most commonly used approaches to generate a Docker image for our microservices. Now, the natural question arises: Which approach is better? Which one should you use?

The truth is, there is no universally "better" approach—each method comes with its own advantages and disadvantages. The choice depends on your specific use case and project requirements.

### **Dockerfile Approach**

The **Dockerfile** approach offers great flexibility, allowing you to customize the image creation process based on specific requirements. However, it comes with some challenges:

- You need expertise in writing Dockerfiles.
- You must manually follow production standards and best practices.
- Maintenance is required for every microservice.

Despite these drawbacks, if you need custom configurations, the Dockerfile approach is the best option.

### **Buildpacks vs. Jib**

To simplify the Docker image creation process, we have two other options: **Buildpacks** and **Jib**.

The **Buildpacks** approach is widely used because it:

- Supports multiple languages.
- Provides advanced caching.
- Offers modular and pluggable features.
- Is a preferred choice for production environments with diverse microservices.

However, **Jib** is another powerful alternative, particularly for Java-based microservices. **Inside this course, we will use Jib**, and here’s why:

1. **Faster Image Generation** – Jib takes significantly less time to create Docker images compared to Buildpacks.
2. **Lower Resource Consumption** – Jib requires less storage and RAM, making it suitable for developers using systems with limited resources.
3. **MacOS Stability Issues with Buildpacks** – While Buildpacks work well in Linux and Windows environments, they can be slow and problematic on macOS.

### **Final Recommendation**

For real-world projects with multi-language microservices, **Buildpacks** is often the better choice. However, for Java-based microservices—especially in local development—**Jib** is faster, lightweight, and easier to use.

Ultimately, all three approaches are valid, and your decision should be based on your project requirements and system constraints.

---

## 10. Pushing Docker Images to Docker Hub

```sh
docker image push docker.io/vikas9dev/accounts:s4
```

**Pushing and Pulling Docker Images from a Remote Repository**:- Now that we have successfully generated Docker images inside our local system, the next crucial step is to make them available for deployment in higher environments such as development, QA, or production servers. Keeping Docker images only in the local system is not practical, as they need to be accessible to deploy on remote servers.

**Pushing Docker Images to a Remote Repository**:- Just like we push our code to GitHub, we also need to push our Docker images to a remote repository. This can be done using Docker Hub or private registries provided by AWS, GCP, Azure, or even GitHub. In this course, we will be using **Docker Hub** as our remote repository.

To push a Docker image from the local system to Docker Hub, use the following command:

```sh
docker image push docker.io/<your-username>/<image-name>:<tag>
```

For example, if your Docker username is **vikas9dev**, and you are pushing the `accounts` microservice with the tag **S4**, the command will be:

```sh
docker image push docker.io/vikas9dev/accounts:S4
```

Since we are already logged into Docker Desktop with our Docker Hub credentials, the CLI will automatically use the saved credentials. If you are not logged in, you may get an **authentication error** and need to log in first using:

```sh
docker login
```

Now, let’s push the **loans** and **cards** microservices as well:

```sh
docker image push docker.io/vikas9dev/loans:S4
docker image push docker.io/vikas9dev/cards:S4
```

Once the images are pushed, we can verify them inside **Docker Hub** by logging into the Docker Hub website. Under our account, we will see the images along with their tags, sizes, and timestamps.

### **Public vs. Private Docker Images**

By default, Docker Hub stores images as **public**, meaning anyone can pull them without credentials. If you want to restrict access, you can change the **visibility settings** to **private** in Docker Hub. However, with a **free plan**, only one image can be private.

To make an image private:

1. Go to Docker Hub → Your Repository.
2. Click on the **Settings** tab.
3. Change the **visibility** to **Private**.

### **Pulling Docker Images from Docker Hub**

If anyone (or a CI/CD pipeline) needs to use your Docker images, they can **pull** them using the following command:

```sh
docker pull docker.io/vikas9dev/cards:S4
```

Let’s test this by removing the **cards** image from the local system and pulling it again:

1. Delete the **cards** Docker image from the system.
2. Run the following command to pull it from Docker Hub:

  ```sh
  docker pull docker.io/vikas9dev/cards:S4
  ```

3. Verify by running:

  ```sh
  docker images
  ```

The image should now be available again inside your local system.

By pushing images to Docker Hub, we ensure they are accessible for deployment. From Docker Hub, teams can pull images manually or use automation tools like **CI/CD pipelines** to deploy them to cloud servers or virtual machines.

With this approach, we can efficiently manage Docker images and ensure smooth deployments across environments.

## 11. Managing Multiple Microservices with Docker Compose

In our current setup, each microservice—**Cards**, **Loans**, and **Accounts**—requires a separate Docker image. To run these services, we must manually execute the `docker run` command for each image, specifying ports and other configurations. This process becomes impractical as the number of microservices increases. Imagine managing **100 microservices**—running `docker run` 100 times is simply not viable.

### Introducing Docker Compose

To streamline this process, Docker provides **Docker Compose**, a tool designed to define and manage multi-container applications. With **Docker Compose**, we can configure all microservices in a single **YAML file** and start them with a **single command**.

Docker Compose provides several advantages:

- Defines **all service configurations** in one place.
- Starts, stops, and manages multiple microservices efficiently.
- Works across **different environments** like development, staging, and production.
- Allocates resources like **memory limits** for containers.
- Supports **networking** between microservices.

### Setting Up a `docker-compose.yml` File

To use **Docker Compose**, we create a **`docker-compose.yml`** file in one of our microservices (e.g., `Accounts`). This file defines all our microservices, their images, port mappings, and resource constraints.

```yaml
services:
  accounts:
    image: vikas9dev/accounts:S4
    container_name: accounts-ms
    ports:
      - "8080:8080"
    deploy:
      resources:
        limits:
          memory: 700M
    networks:
      - PeopleBank

  loans:
    image: vikas9dev/loans:S4
    container_name: loans-ms
    ports:
      - "8090:8090"
    deploy:
      resources:
        limits:
          memory: 700M
    networks:
      - PeopleBank

  cards:
    image: vikas9dev/cards:S4
    container_name: cards-ms
    ports:
      - "9000:9000"
    deploy:
      resources:
        limits:
          memory: 700M
    networks:
      - PeopleBank

networks:
  PeopleBank:
    driver: bridge
```

This configuration ensures that:

- All microservices run in a **common network** (`PeopleBank`).
- Each microservice has a **fixed container name**.
- Ports are **mapped** correctly for external access.
- Memory usage is **limited to 700MB** per service.

### Running Microservices with Docker Compose

Once our **`docker-compose.yml`** file is ready, we can start all microservices using:

```sh
docker compose up -d
```

This command:

- **Creates** and **starts** all services.
- Runs them in **detached mode (`-d`)**, so the terminal remains free.
- Uses **existing containers** if they already exist.

To verify running containers:

```sh
docker ps
```

### Stopping and Restarting Services

Stopping all microservices:

```sh
docker compose down
```

Stopping without deleting containers:

```sh
docker compose stop
```

Restarting stopped containers:

```sh
docker compose start
```

If containers are removed, we must use `docker compose up` to **recreate them**.

Using **Docker Compose**, we can efficiently manage multiple microservices with minimal effort. Instead of manually handling each service, we define everything in a structured YAML file and use **simple commands** to start, stop, or restart services. This approach saves time and ensures a **consistent environment** across different stages of development.

---

## **12. Essential Docker Commands for Day-to-Day Usage**

To efficiently manage Docker containers and images, it's crucial to be familiar with the most commonly used commands. Below, we've categorized them for better clarity.

---

### **1. Image Management** 🏗️

- **List all images:**
  ```sh
  docker images
  ```
- **Inspect a specific image:**
  ```sh
  docker image inspect <image_id>
  ```
- **Build an image from a Dockerfile:**
  ```sh
  docker build -t <image_name>:<tag> .
  ```
- **Remove an image:**
  ```sh
  docker image rm <image_id>
  ```
- **Remove multiple images:**
  ```sh
  docker image rm <image_id1> <image_id2>
  ```

---

### **2. Container Management** 📦

- **Run a container from an image:**
  ```sh
  docker run -p <host_port>:<container_port> <image_name>
  ```
- **List running containers:**
  ```sh
  docker ps
  ```
- **List all containers (including stopped ones):**
  ```sh
  docker ps -a
  ```
- **Start a stopped container:**
  ```sh
  docker container start <container_id>
  ```
- **Restart a container:**
  ```sh
  docker container restart <container_id>
  ```
- **Pause a running container:**
  ```sh
  docker container pause <container_id>
  ```
- **Unpause a paused container:**
  ```sh
  docker container unpause <container_id>
  ```
- **Stop a running container (gracefully):**
  ```sh
  docker container stop <container_id>
  ```
- **Kill a container instantly:**
  ```sh
  docker container kill <container_id>
  ```

---

### **3. Debugging & Monitoring** 🔍

- **View container details:**
  ```sh
  docker container inspect <container_id>
  ```
- **View container logs:**
  ```sh
  docker container logs <container_id>
  ```
- **Follow logs in real-time:**
  ```sh
  docker container logs -f <container_id>
  ```
- **View live CPU, memory, and I/O usage:**
  ```sh
  docker container stats
  ```
- **Inspect an image’s history:**
  ```sh
  docker history <image_name>
  ```

---

### **4. Removing Containers & Cleanup** 🗑️

- **Remove a specific container:**
  ```sh
  docker rm <container_id>
  ```
- **Remove all stopped containers:**
  ```sh
  docker container prune
  ```
- **Remove unused images:**
  ```sh
  docker image prune
  ```
- **Remove all unused images, stopped containers, and networks:**
  ```sh
  docker system prune
  ```

---

### **5. Docker Hub & Registry Commands** 🌍

- **Pull an image from Docker Hub:**
  ```sh
  docker pull <image_name>
  ```
- **Push an image to Docker Hub:**
  ```sh
  docker push <image_name>
  ```
- **Log in to Docker Hub:**
  ```sh
  docker login -u <username>
  ```
- **Log out from Docker Hub:**
  ```sh
  docker logout
  ```

---

### **6. Running Commands Inside a Container** 🖥️

- **Open a shell inside a running container:**
  ```sh
  docker exec -it <container_id> sh
  ```

---

### **7. Docker Compose Commands** ⚙️

- **Start all services from a `docker-compose.yml` file:**
  ```sh
  docker compose up -d
  ```
- **Stop and remove all services:**
  ```sh
  docker compose down
  ```
- **Stop services without removing containers:**
  ```sh
  docker compose stop
  ```
- **Restart stopped services without recreating containers:**
  ```sh
  docker compose start
  ```

---

These categorized Docker commands cover everything from **image and container management** to **debugging, cleanup, and Docker Compose usage**. Whether you're a developer, DevOps engineer, or preparing for an interview, mastering these commands will make Docker management seamless.

---

## **13. Enhancing Docker with Extensions**

Docker **Extensions** add powerful features to **Docker Desktop**, making container management easier. You can find them under **"Add Extensions"** in Docker Desktop and install tools that fit your needs.

### **Logs Explorer – A Must-Have Extension**

**Logs Explorer** helps view logs from running and stopped containers in one place.

#### **Installation & Usage:**

1. Open **Docker Desktop** → **Extensions** → Search **"Logs Explorer"**.
2. Click **"Install"** (Officially published by Docker).
3. Start containers using:
   ```sh
   docker compose up -d
   ```
4. Open **Logs Explorer** to view logs by **service name, color-coded logs, search filters**, and more.

### **Why Use Docker Extensions?**

- Save time with tools like **Logs Explorer, Database Managers, Security Scanners**.
- Automate tasks instead of doing them manually.
- Easily find solutions for **common Docker challenges**.

---
